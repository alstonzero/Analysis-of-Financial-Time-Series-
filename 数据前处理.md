### 数据前处理

```python
pip install tensorflow
pip install keras
```



```python
import pandas as pd
import matplotlib.pyplot as plt
from pandas import read_excel
import numpy as np
from pandas import DataFrame
from pandas import concat
from sklearn.preprocessing import MinMaxScaler
from keras.models import Sequential
from keras.layers import LSTM,Dense,Dropout
from numpy import concatenate
from sklearn.metrics import mean_squared_error,mean_absolute_error,r2_score
from math import sqrt
```

#### date列解析为日期时间格式,并设为索引index

```python
nikkei = pd.read_csv("nikkei_stock_average_daily_jp.csv",parse_dates=['date'],index_col="date") #
nikkei.head()
```



```python
# 增加一列'earn_rate', 存储每日的收益率
nikkei['earn_rate'] = nikkei['close'].pct_change()
nikkei['earn_rate'].fillna(method='bfill',inplace=True)
nikkei.head()
```

|            |    close |     open |     high |      low | earn_rate |
| ---------: | -------: | -------: | -------: | -------: | --------: |
|       date |          |          |          |          |           |
| 2016-01-04 | 18450.98 | 18818.58 | 18951.12 | 18394.43 | -0.004172 |
| 2016-01-05 | 18374.00 | 18398.76 | 18547.38 | 18327.52 | -0.004172 |

```python
#获取DataFrame中的数据，形式为数组array形式
values=nikkei.values
#确保所有数据为float类型
values=values.astype('float32')
 
# 特征的归一化处理
scaler = MinMaxScaler(feature_range=(0, 1))
scaled = scaler.fit_transform(values)
print(scaled)
```

```
[[0.3754815  0.40121603 0.3975364  0.3774538  0.49772465]
 [0.36722052 0.35598385 0.35328662 0.37030017 0.49772465]
 [0.3476168  0.3572564  0.3447379  0.3421582  0.45945403]
 ...
 [0.97805464 0.9692881  0.96087825 0.9763986  0.5568996 ]
 [0.96392286 0.96197796 0.955943   0.96815    0.48910326]
 [0.95645607 0.9499314  0.9449216  0.95916164 0.5061149 ]]
```

```python
x = scaled
y = scaled[:,0] #close as label
dataX = []
dataY = []
seq_length = 7 #7个一组，前7天预测第8天价格
for i in range(0,len(y)-seq_length):
    _x = x[i:i+seq_length]
    _y = y[i+seq_length]
    dataX.append(_x)
    dataY.append(_y)

train_size = int(len(dataY)*0.7) #training data
test_size  = len(dataY)-train_size
trainX,testX = np.array(dataX[0:train_size]),np.array(dataX[train_size:len(dataX)])
trainY,testY = np.array(dataY[0:train_size]),np.array(dataY[train_size:len(dataY)])
```



```python
import tensorflow.compat.v1 as tf
tf.disable_v2_behavior()
```

```python
X = tf.placeholder(tf.float32,[None,seq_length,data_dim],name='input_X')
Y = tf.placeholder(tf.float32,[None,1],name='input_Y')
```



```
cell =tf.nn.rnn_cell.LSTMCell(num_units=hidden_dim,activation=tf.tanh,use_peepholes=True)
outputs,states=tf.nn.dynamic_rnn(cell=cell,inputs=X,dtype=tf.float32)
```



```python
Y_pred = outputs[:,-1]
loss = tf.reduce_sum(tf.square(Y_pred-Y),name="losses_sum")
optimizer = tf.train.AdamOptimizer(learning_rate)
train = optimizer.minimize(loss,name='train')
```



```python
targets = tf.placeholder(tf.float32,[None,1],name='targets')
predictions = tf.placeholder(tf.float32,[None,1],name='predictions')
rmse = tf.sqrt(tf.reduce_mean(tf.square(targets-predictions)),name='rmse')
with tf.Session() as sess:
    #使用tf.global_variables_initializer()
    #添加节点用于初始化所有的变量
    init = tf.global_variables_initializer()
    sess.run(init)
    
    merged = tf.summary.merge_all()
    writer = tf.summary.FileWriter("./tensorflowlog",sess.graph)
    losslist = []
    #Training step
    for i in range(iterations):
        _,step_loss = sess.run([train,loss],feed_dict={X:trainX,Y:trainY})
        print("[step:{}]loss:{}".format(i,step_loss))
        losslist = np.append(losslist,step_loss)
    
    #Test step
    test_predict = sess.run(Y_pred,feed_dict={X:testX})
    rmse = sess.run(rmse,feed_dict={targets:testY,predictions:test_predict})
    print("RMSE:{}".format(rmse))
    #
    print("train_size:{}".format(train_size))
    print("test_size:{}".format(test_size))
```

